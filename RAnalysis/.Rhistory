Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
# tail(Probe.Data) # to view the newest data and compare to APEX fusion for assigning column names
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Output/20190805_Apex_Data_Output.data.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Graphs/20190805_Apex_Data_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(10, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(3.5, 8.5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Graphs/20190805_Apex_Data_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(15, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(6, 8.5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
ed reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=190809&days=7") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
head(Apex.Data) # check the first few lines to see the first few hrs of the extracted data
tail(Apex.Data) # check to end to dertmine if the xmlParse extracted up to present day
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
tail(Apex.Data2) # check most recent data
names(Apex.Data2)
tail(Apex.Data2) # check most recent data
# Column names modified as of 20190220 - new apex (from broodstock set-up) moved to conicals due to a malfunction
# Date.Time = column 3
# TMP_T0 = column 6
# pH_T0= column 9
# TMP_T4 = column 69
# pH_T4 = column 72
# TMP_T6 = column 75
# pH_T6 = column 78
# TMP_T5 = column 81
# pH_T5 = column 84
# TMP_T1 = column 87
# pH_T1 = column 90
# TMP_T7 = column 93
# pH_T7 = column 96
# TMP_T3 = column 99
# pH_T3 = column 102
# TMP_T2 = column 105
# pH_T2 = column 108 pH_T2
# NOTE: 18 in total above
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,69,72,75,78,81,84,87,90,93,96,99,102,105,108)] #select columns
colnames(Probe.Data) <- c("Date.Time", "TMP_T0", "pH_T0", "TMP_T4", "pH_T4", "TMP_T6","pH_T6",
"TMP_T5", "pH_T5", "TMP_T1", "pH_T1", "TMP_T7", "pH_T7", "TMP_T3",
"pH_T3", "TMP_T2", "pH_T2")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
# tail(Probe.Data) # to view the newest data and compare to APEX fusion for assigning column names
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Output/20190815_Apex_Data_Output.data.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Graphs/20190815_Apex_Data_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(15, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(6, 8.5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
#Title: Juvenile Resp.LoLin.plots
#Author: Sam Gurr
#Edited by: Sam Gurr
#Date Last Modified: 20191002 - follow-up to peer review to show resulting plots
#See Readme file for details
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
#CHANGE LINE 52 TO CALL NEW DATA
# Set Working Directory:
# setwd("~/MyProjects/Geoduck_Conditioning/RAnalysis/") #set working
setwd("C:/Users/samjg/Documents/My_Projects/Juvenile_geoduck_OA/RAnalysis/Data/SDR_data")
#Load Sample Info
#Sample.Info <- read.csv(file="Data/SDR_data/REFERENCE_number.individuals_shell.size.csv", header=T) #read sample.info data
# CHANGE THE FOLLOWING ..THEN CONTROL A + ENTER
# Respiration File
path.p<-"/All_resp_data" #the location of all your respirometry files
a <- 0.4
ouputNAME<-"Data/SDR_data/Cumulative_resp_alpha0.4.csv"
# bring in the respiration file names CHANGE LINE 53 TO RUN NEW DATASETS
file.names.full<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
file.names
# CHANGE THE FOLLOWING ..THEN CONTROL A + ENTER
# Respiration File
path.p<-"/All_data_csv" #the location of all your respirometry files
a <- 0.4
ouputNAME<-"Data/SDR_data/All_data_csv"
# bring in the respiration file names CHANGE LINE 53 TO RUN NEW DATASETS
file.names.full<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
file.names <- file.names.full[c(25:28)] # call the files you want to analyze and rbind to the current cumunaltive file
file.names # look at the names of the csv files you will call in the following for loop
file.names <- file.names.full[c(20:21)] # call the files you want to analyze and rbind to the current cumunaltive file
file.names # look at the names of the csv files you will call in the following for loop
file.names.full
path.p
# CHANGE THE FOLLOWING ..THEN CONTROL A + ENTER
# Respiration File
path.p<-"/All_data_csv/" #the location of all your respirometry files
a <- 0.4
ouputNAME<-"Data/SDR_data/All_data_csv"
# bring in the respiration file names CHANGE LINE 53 TO RUN NEW DATASETS
file.names.full<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
file.names.full
file.names.full
# Set Working Directory:
# setwd("~/MyProjects/Geoduck_Conditioning/RAnalysis/") #set working
setwd("C:/Users/samjg/Documents/My_Projects/Juvenile_geoduck_OA/RAnalysis/Data/SDR_data")
# CHANGE THE FOLLOWING ..THEN CONTROL A + ENTER
# Respiration File
path.p<-"/All_data_csv" #the location of all your respirometry files
a <- 0.4
ouputNAME<-"Data/SDR_data/All_data_csv"
# bring in the respiration file names CHANGE LINE 53 TO RUN NEW DATASETS
file.names.full<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
file.names.full
# Set Working Directory:
# setwd("~/MyProjects/Geoduck_Conditioning/RAnalysis/") #set working
setwd("C:/Users/samjg/Documents/My_Projects/Juvenile_geoduck_OA/RAnalysis/")
# CHANGE THE FOLLOWING ..THEN CONTROL A + ENTER
# Respiration File
path.p<-"Data/SDR_data/All_data_csv" #the location of all your respirometry files
a <- 0.4
ouputNAME<-"Data/SDR_data/All_data_csv"
# bring in the respiration file names CHANGE LINE 53 TO RUN NEW DATASETS
file.names.full<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
file.names.full
file.names <- file.names.full[c(2:20)] # call the files you want to analyze and rbind to the current cumunaltive file
file.names # look at the names of the csv files you will call in the following for loop
file.names
file.names
file.names <- file.names.full[c(2:17)] # call the files you want to analyze and rbind to the current cumunaltive file
file.names # look at the names of the csv files you will call in the following for loop
df_total <- data.frame() # start dataframe
resp.table <- data.frame(matrix(nrow = 1, ncol = 7)) # create dataframe to save cumunalitively during for loop
colnames(resp.table)<-c('Date', 'RUN', 'SDR_position', 'Lpc', 'Leq' , 'Lz', 'alpha') # names for comuns in the for loop
for(i in 1:length(file.names)) { # for every file in list start at the first and run this following function
Resp.Data <-read.table(file.path(path.p,file.names[i]), skip = 56, header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Time.Min. <- seq.int(0.017, (nrow(Resp.Data))*0.25, by=0.25) #set time in min
#Resp.Data[Resp.Data[,] == "No Sensor"] <- as.numeric(runif(nrow(Resp.Data), min=0, max=300)) #convert any vials with no data
Resp.Data <- Resp.Data[,2:27] #use only res values - 24 total in the 24 well plate (SDR SensorDish)
# Resp.Data <- Resp.Data[20:89,] # truncated for 5-20 minnute record (used for juv geoduck 20190116)
# tail(Resp.Data) # check the dataset
for(j in 2:(ncol(Resp.Data)-1)){
model <- rankLocReg(
xall=Resp.Data$Time.Min., yall=as.numeric(Resp.Data[, j]),
alpha=a, method="pc", verbose=TRUE) # run the LoLin script
sum.table<-summary(model)
resp.table$Date <- substr(file.names[i], 1,8) # all files have date in the form of yyyymmdd at the start of each csv name
resp.table$RUN <- substr(file.names[i], 15,15) # assign the run to the number in the title for the trials completed that day
resp.table$SDR_position <- colnames(Resp.Data[j]) # assign the vial position - this will be related to contents (blank or individuals) later in script
resp.table$alpha <- a # set at start of script - reresents the proportion of data for final estimate of slopes (Lpc, Leq, Lz)
resp.table$Lpc <-sum.table$Lcompare[3,6] # Lpc slope
resp.table$Leq <-sum.table$Lcompare[2,6] # Leq slope
resp.table$Lz <-sum.table$Lcompare[1,6]  # Lz slope
#resp.table$ci.Lz<-sum.table$Lcompare[1,9]
#resp.table$ci.Leq<-sum.table$Lcompare[2,9]
#resp.table$ci.Lpc<-sum.table$Lcompare[3,9]
df <- data.frame(resp.table) # name dataframe for this singl e row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
# save plots every inside loop and name by date_run_vialposition
pdf(paste0("C:/Users/samjg/Documents/My_Projects/Juvenile_geoduck_OA/RAnalysis/Data/SDR_data/All_data_csv/plots_alpha0.4/",substr(file.names[i], 1,8),"_", "RUN",substr(file.names[i], 15,15),"_",colnames(Resp.Data[j]),"_regression.pdf"))
plot(model)
dev.off()
} # end of inside for loop
} # end of outside for loop
for(i in 1:length(file.names)) { # for every file in list start at the first and run this following function
Resp.Data <-read.table(file.path(path.p,file.names[i]), skip = 56, header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Time.Min. <- seq.int(0.017, (nrow(Resp.Data))*0.25, by=0.25) #set time in min
#Resp.Data[Resp.Data[,] == "No Sensor"] <- as.numeric(runif(nrow(Resp.Data), min=0, max=300)) #convert any vials with no data
Resp.Data <- Resp.Data[,2:27] #use only res values - 24 total in the 24 well plate (SDR SensorDish)
# Resp.Data <- Resp.Data[20:89,] # truncated for 5-20 minnute record (used for juv geoduck 20190116)
# tail(Resp.Data) # check the dataset
for(j in 2:(ncol(Resp.Data)-1)){
model <- rankLocReg(
xall=Resp.Data$Time.Min., yall=as.numeric(Resp.Data[, j]),
alpha=a, method="pc", verbose=TRUE) # run the LoLin script
sum.table<-summary(model)
resp.table$Date <- substr(file.names[i], 1,8) # all files have date in the form of yyyymmdd at the start of each csv name
resp.table$RUN <- substr(file.names[i], 15,15) # assign the run to the number in the title for the trials completed that day
resp.table$SDR_position <- colnames(Resp.Data[j]) # assign the vial position - this will be related to contents (blank or individuals) later in script
resp.table$alpha <- a # set at start of script - reresents the proportion of data for final estimate of slopes (Lpc, Leq, Lz)
resp.table$Lpc <-sum.table$Lcompare[3,6] # Lpc slope
resp.table$Leq <-sum.table$Lcompare[2,6] # Leq slope
resp.table$Lz <-sum.table$Lcompare[1,6]  # Lz slope
#resp.table$ci.Lz<-sum.table$Lcompare[1,9]
#resp.table$ci.Leq<-sum.table$Lcompare[2,9]
#resp.table$ci.Lpc<-sum.table$Lcompare[3,9]
df <- data.frame(resp.table) # name dataframe for this singl e row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
# save plots every inside loop and name by date_run_vialposition
pdf(paste0("C:/Users/samjg/Documents/My_Projects/Juvenile_geoduck_OA/RAnalysis/Data/SDR_data/All_data_csv/plots_alpha0.4/",substr(file.names[i], 1,8),"_", "RUN",substr(file.names[i], 15,15),"_",colnames(Resp.Data[j]),"_regression.pdf"))
plot(model)
dev.off()
} # end of inside for loop
} # end of outside for loop
file.names
for(i in 1:length(file.names)) { # for every file in list start at the first and run this following function
Resp.Data <-read.table(file.path(path.p,file.names[i]), skip = 56, header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Time.Min. <- seq.int(0.017, (nrow(Resp.Data))*0.25, by=0.25) #set time in min
#Resp.Data[Resp.Data[,] == "No Sensor"] <- as.numeric(runif(nrow(Resp.Data), min=0, max=300)) #convert any vials with no data
Resp.Data <- Resp.Data[,2:27] #use only res values - 24 total in the 24 well plate (SDR SensorDish)
# Resp.Data <- Resp.Data[20:89,] # truncated for 5-20 minnute record (used for juv geoduck 20190116)
# tail(Resp.Data) # check the dataset
for(j in 2:(ncol(Resp.Data)-1)){
model <- rankLocReg(
xall=Resp.Data$Time.Min., yall=as.numeric(Resp.Data[, j]),
alpha=a, method="pc", verbose=TRUE) # run the LoLin script
sum.table<-summary(model)
resp.table$Date <- substr(file.names[i], 1,8) # all files have date in the form of yyyymmdd at the start of each csv name
resp.table$RUN <- substr(file.names[i], 15,15) # assign the run to the number in the title for the trials completed that day
resp.table$SDR_position <- colnames(Resp.Data[j]) # assign the vial position - this will be related to contents (blank or individuals) later in script
resp.table$alpha <- a # set at start of script - reresents the proportion of data for final estimate of slopes (Lpc, Leq, Lz)
resp.table$Lpc <-sum.table$Lcompare[3,6] # Lpc slope
resp.table$Leq <-sum.table$Lcompare[2,6] # Leq slope
resp.table$Lz <-sum.table$Lcompare[1,6]  # Lz slope
#resp.table$ci.Lz<-sum.table$Lcompare[1,9]
#resp.table$ci.Leq<-sum.table$Lcompare[2,9]
#resp.table$ci.Lpc<-sum.table$Lcompare[3,9]
df <- data.frame(resp.table) # name dataframe for this singl e row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
# save plots every inside loop and name by date_run_vialposition
pdf(paste0("C:/Users/samjg/Documents/My_Projects/Juvenile_geoduck_OA/RAnalysis/Data/SDR_data/All_data_csv/plots_alpha0.4/",substr(file.names[i], 1,8),"_", "RUN",substr(file.names[i], 23,24),"_",colnames(Resp.Data[j]),"_regression.pdf"))
plot(model)
dev.off()
} # end of inside for loop
} # end of outside for loop
substr(file.names[i], 1,8),"_", "RUN",substr(file.names[i], 23,24)
substr(file.names[i], 23,24)
colnames(Resp.Data[j])
Resp.Data[j]
for(i in 1:length(file.names)) { # for every file in list start at the first and run this following function
Resp.Data <-read.table(file.path(path.p,file.names[i]), header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Time.Min. <- seq.int(0.017, (nrow(Resp.Data))*0.25, by=0.25) #set time in min
#Resp.Data[Resp.Data[,] == "No Sensor"] <- as.numeric(runif(nrow(Resp.Data), min=0, max=300)) #convert any vials with no data
Resp.Data <- Resp.Data[,2:27] #use only res values - 24 total in the 24 well plate (SDR SensorDish)
# Resp.Data <- Resp.Data[20:89,] # truncated for 5-20 minnute record (used for juv geoduck 20190116)
# tail(Resp.Data) # check the dataset
for(j in 2:(ncol(Resp.Data)-1)){
model <- rankLocReg(
xall=Resp.Data$Time.Min., yall=as.numeric(Resp.Data[, j]),
alpha=a, method="pc", verbose=TRUE) # run the LoLin script
sum.table<-summary(model)
resp.table$Date <- substr(file.names[i], 1,8) # all files have date in the form of yyyymmdd at the start of each csv name
resp.table$RUN <- substr(file.names[i], 15,15) # assign the run to the number in the title for the trials completed that day
resp.table$SDR_position <- colnames(Resp.Data[j]) # assign the vial position - this will be related to contents (blank or individuals) later in script
resp.table$alpha <- a # set at start of script - reresents the proportion of data for final estimate of slopes (Lpc, Leq, Lz)
resp.table$Lpc <-sum.table$Lcompare[3,6] # Lpc slope
resp.table$Leq <-sum.table$Lcompare[2,6] # Leq slope
resp.table$Lz <-sum.table$Lcompare[1,6]  # Lz slope
#resp.table$ci.Lz<-sum.table$Lcompare[1,9]
#resp.table$ci.Leq<-sum.table$Lcompare[2,9]
#resp.table$ci.Lpc<-sum.table$Lcompare[3,9]
df <- data.frame(resp.table) # name dataframe for this singl e row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
# save plots every inside loop and name by date_run_vialposition
pdf(paste0("C:/Users/samjg/Documents/My_Projects/Juvenile_geoduck_OA/RAnalysis/Data/SDR_data/All_data_csv/plots_alpha0.4/",substr(file.names[i], 1,8),"_", "RUN",substr(file.names[i], 23,24),"_",colnames(Resp.Data[j]),"_regression.pdf"))
plot(model)
dev.off()
} # end of inside for loop
} # end of outside for loop
Resp.Data
Resp.Data <- Resp.Data[,2:27]
Resp.Data
Resp.Data[, j]
xall
yall
for(i in 1:length(file.names)) { # for every file in list start at the first and run this following function
Resp.Data <-read.table(file.path(path.p,file.names[i]), skip = 56, header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Time.Min. <- seq.int(0.017, (nrow(Resp.Data))*0.25, by=0.25) #set time in min
#Resp.Data[Resp.Data[,] == "No Sensor"] <- as.numeric(runif(nrow(Resp.Data), min=0, max=300)) #convert any vials with no data
Resp.Data <- Resp.Data[,2:27] #use only res values - 24 total in the 24 well plate (SDR SensorDish)
# Resp.Data <- Resp.Data[20:89,] # truncated for 5-20 minnute record (used for juv geoduck 20190116)
# tail(Resp.Data) # check the dataset
for(j in 2:(ncol(Resp.Data)-1)){
model <- rankLocReg(
xall=Resp.Data$Time.Min., yall=as.numeric(Resp.Data[, j]),
alpha=a, method="pc", verbose=TRUE) # run the LoLin script
sum.table<-summary(model)
resp.table$Date <- substr(file.names[i], 1,8) # all files have date in the form of yyyymmdd at the start of each csv name
resp.table$RUN <- substr(file.names[i], 15,15) # assign the run to the number in the title for the trials completed that day
resp.table$SDR_position <- colnames(Resp.Data[j]) # assign the vial position - this will be related to contents (blank or individuals) later in script
resp.table$alpha <- a # set at start of script - reresents the proportion of data for final estimate of slopes (Lpc, Leq, Lz)
resp.table$Lpc <-sum.table$Lcompare[3,6] # Lpc slope
resp.table$Leq <-sum.table$Lcompare[2,6] # Leq slope
resp.table$Lz <-sum.table$Lcompare[1,6]  # Lz slope
#resp.table$ci.Lz<-sum.table$Lcompare[1,9]
#resp.table$ci.Leq<-sum.table$Lcompare[2,9]
#resp.table$ci.Lpc<-sum.table$Lcompare[3,9]
df <- data.frame(resp.table) # name dataframe for this singl e row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
# save plots every inside loop and name by date_run_vialposition
pdf(paste0("C:/Users/samjg/Documents/My_Projects/Juvenile_geoduck_OA/RAnalysis/Data/SDR_data/All_data_csv/plots_alpha0.4/",substr(file.names[i], 1,8),"_", "RUN",substr(file.names[i], 23,24),"_",colnames(Resp.Data[j]),"_regression.pdf"))
plot(model)
dev.off()
} # end of inside for loop
} # end of outside for loop
xall
yall
method
sum.table
model
resp.table$Date
resp.table$RUN
resp.table$SDR_position
colnames(Resp.Data[j])
Resp.Data[j]
Resp.Data
Resp.Data[,2:27]
Resp.Data
for(i in 1:length(file.names)) { # for every file in list start at the first and run this following function
Resp.Data <-read.table(file.path(path.p,file.names[i]), skip = 56, header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Time.Min. <- seq.int(0.017, (nrow(Resp.Data))*0.25, by=0.25) #set time in min
#Resp.Data[Resp.Data[,] == "No Sensor"] <- as.numeric(runif(nrow(Resp.Data), min=0, max=300)) #convert any vials with no data
Resp.Data <- Resp.Data[,2:27] #use only res values - 24 total in the 24 well plate (SDR SensorDish)
# Resp.Data <- Resp.Data[20:89,] # truncated for 5-20 minnute record (used for juv geoduck 20190116)
# tail(Resp.Data) # check the dataset
for(j in 2:(ncol(Resp.Data)-1)){
model <- rankLocReg(
xall=Resp.Data$Time.Min., yall=as.numeric(Resp.Data[, j]),
alpha=a, method="pc", verbose=TRUE) # run the LoLin script
sum.table<-summary(model)
resp.table$Date <- substr(file.names[i], 1,8) # all files have date in the form of yyyymmdd at the start of each csv name
resp.table$RUN <- substr(file.names[i], 23,24) # assign the run to the number in the title for the trials completed that day
resp.table$SDR_position <- colnames(Resp.Data[j]) # assign the vial position - this will be related to contents (blank or individuals) later in script
resp.table$alpha <- a # set at start of script - reresents the proportion of data for final estimate of slopes (Lpc, Leq, Lz)
resp.table$Lpc <-sum.table$Lcompare[3,6] # Lpc slope
resp.table$Leq <-sum.table$Lcompare[2,6] # Leq slope
resp.table$Lz <-sum.table$Lcompare[1,6]  # Lz slope
#resp.table$ci.Lz<-sum.table$Lcompare[1,9]
#resp.table$ci.Leq<-sum.table$Lcompare[2,9]
#resp.table$ci.Lpc<-sum.table$Lcompare[3,9]
df <- data.frame(resp.table) # name dataframe for this singl e row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
# save plots every inside loop and name by date_run_vialposition
pdf(paste0("C:/Users/samjg/Documents/My_Projects/Juvenile_geoduck_OA/RAnalysis/Data/SDR_data/All_data_csv/plots_alpha0.4/",substr(file.names[i], 1,8),"_", "RUN",substr(file.names[i], 23,24),"_",colnames(Resp.Data[j]),"_regression.pdf"))
plot(model)
dev.off()
} # end of inside for loop
} # end of outside for loop
Resp.Data
Resp.Data[,2:27]
Resp.Data
Resp.Data
Resp.Data <-read.table(file.path(path.p,file.names[i]), header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data
Resp.Data <-read.table(file.path(path.p,file.names[i]), header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Time.Min. <- seq.int(0.017, (nrow(Resp.Data))*0.25, by=0.25) #set time in min
#Resp.Data[Resp.Data[,] == "No Sensor"] <- as.numeric(runif(nrow(Resp.Data), min=0, max=300)) #convert any vials with no data
Resp.Data <- Resp.Data[,2:27]
Resp.Data[,2:27]
for(i in 1:length(file.names)) { # for every file in list start at the first and run this following function
Resp.Data <-read.table(file.path(path.p,file.names[i]), header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Time.Min. <- seq.int(0.017, (nrow(Resp.Data))*0.25, by=0.25) #set time in min
#Resp.Data[Resp.Data[,] == "No Sensor"] <- as.numeric(runif(nrow(Resp.Data), min=0, max=300)) #convert any vials with no data
Resp.Data <- Resp.Data[,2:27] #use only res values - 24 total in the 24 well plate (SDR SensorDish)
# Resp.Data <- Resp.Data[20:89,] # truncated for 5-20 minnute record (used for juv geoduck 20190116)
# tail(Resp.Data) # check the dataset
for(j in 2:(ncol(Resp.Data)-1)){
model <- rankLocReg(
xall=Resp.Data$Time.Min., yall=as.numeric(Resp.Data[, j]),
alpha=a, method="pc", verbose=TRUE) # run the LoLin script
sum.table<-summary(model)
resp.table$Date <- substr(file.names[i], 1,8) # all files have date in the form of yyyymmdd at the start of each csv name
resp.table$RUN <- substr(file.names[i], 23,24) # assign the run to the number in the title for the trials completed that day
resp.table$SDR_position <- colnames(Resp.Data[j]) # assign the vial position - this will be related to contents (blank or individuals) later in script
resp.table$alpha <- a # set at start of script - reresents the proportion of data for final estimate of slopes (Lpc, Leq, Lz)
resp.table$Lpc <-sum.table$Lcompare[3,6] # Lpc slope
resp.table$Leq <-sum.table$Lcompare[2,6] # Leq slope
resp.table$Lz <-sum.table$Lcompare[1,6]  # Lz slope
#resp.table$ci.Lz<-sum.table$Lcompare[1,9]
#resp.table$ci.Leq<-sum.table$Lcompare[2,9]
#resp.table$ci.Lpc<-sum.table$Lcompare[3,9]
df <- data.frame(resp.table) # name dataframe for this singl e row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
# save plots every inside loop and name by date_run_vialposition
pdf(paste0("C:/Users/samjg/Documents/My_Projects/Juvenile_geoduck_OA/RAnalysis/Data/SDR_data/All_data_csv/plots_alpha0.4/",substr(file.names[i], 1,8),"_", "RUN",substr(file.names[i], 23,24),"_",colnames(Resp.Data[j]),"_regression.pdf"))
plot(model)
dev.off()
} # end of inside for loop
} # end of outside for loop
Resp.Data
Resp.Data <- Resp.Data[,2:20]
Resp.Data
Resp.Data <- Resp.Data[,2:23]
Resp.Data <- Resp.Data[,2:22]
Resp.Data <- Resp.Data[,2:21]
Resp.Data <- Resp.Data[,2:20]
for(i in 1:length(file.names)) { # for every file in list start at the first and run this following function
Resp.Data <-read.table(file.path(path.p,file.names[i]), header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Time.Min. <- seq.int(0.017, (nrow(Resp.Data))*0.25, by=0.25) #set time in min
#Resp.Data[Resp.Data[,] == "No Sensor"] <- as.numeric(runif(nrow(Resp.Data), min=0, max=300)) #convert any vials with no data
Resp.Data <- Resp.Data[,2:26] #use only res values - 24 total in the 24 well plate (SDR SensorDish)
# Resp.Data <- Resp.Data[20:89,] # truncated for 5-20 minnute record (used for juv geoduck 20190116)
# tail(Resp.Data) # check the dataset
for(j in 2:(ncol(Resp.Data)-1)){
model <- rankLocReg(
xall=Resp.Data$Time.Min., yall=as.numeric(Resp.Data[, j]),
alpha=a, method="pc", verbose=TRUE) # run the LoLin script
sum.table<-summary(model)
resp.table$Date <- substr(file.names[i], 1,8) # all files have date in the form of yyyymmdd at the start of each csv name
resp.table$RUN <- substr(file.names[i], 23,24) # assign the run to the number in the title for the trials completed that day
resp.table$SDR_position <- colnames(Resp.Data[j]) # assign the vial position - this will be related to contents (blank or individuals) later in script
resp.table$alpha <- a # set at start of script - reresents the proportion of data for final estimate of slopes (Lpc, Leq, Lz)
resp.table$Lpc <-sum.table$Lcompare[3,6] # Lpc slope
resp.table$Leq <-sum.table$Lcompare[2,6] # Leq slope
resp.table$Lz <-sum.table$Lcompare[1,6]  # Lz slope
#resp.table$ci.Lz<-sum.table$Lcompare[1,9]
#resp.table$ci.Leq<-sum.table$Lcompare[2,9]
#resp.table$ci.Lpc<-sum.table$Lcompare[3,9]
df <- data.frame(resp.table) # name dataframe for this singl e row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
# save plots every inside loop and name by date_run_vialposition
pdf(paste0("C:/Users/samjg/Documents/My_Projects/Juvenile_geoduck_OA/RAnalysis/Data/SDR_data/All_data_csv/plots_alpha0.4/",substr(file.names[i], 1,8),"_", "RUN",substr(file.names[i], 23,24),"_",colnames(Resp.Data[j]),"_regression.pdf"))
plot(model)
dev.off()
} # end of inside for loop
} # end of outside for loop
